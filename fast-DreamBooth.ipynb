{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18MhcgMRmUlb"
      },
      "source": [
        "# **DreamBooth colab From https://github.com/TheLastBen/fast-stable-diffusion, if you face any issues, feel free to discuss them.** \n",
        "Run this Notebook manually step by step, don't miss any, the colab is still in progress, trying to find the best settings for Dreambooth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A4Bae3VP6UsE",
        "outputId": "defa948e-3f2a-4876-9244-9996c386bc8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbKbx185zqlz"
      },
      "source": [
        "# Setting up the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "QyvcqeiL65Tj"
      },
      "outputs": [],
      "source": [
        "#@markdown # Dependencies\n",
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install git+https://github.com/TheLastBen/diffusers\n",
        "%pip install transformers\n",
        "%pip install ftfy\n",
        "%pip install accelerate==0.12.0\n",
        "%pip install bitsandbytes\n",
        "%pip install -q triton==2.0.0.dev20220701\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "1pld5ps87a1q",
        "outputId": "c923341a-34c7-476f-91e1-eb793d5d11c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE !\n"
          ]
        }
      ],
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('it seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl  \n",
        "\n",
        "clear_output()\n",
        "print('DONE !')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3SsbIlxw66N"
      },
      "source": [
        "# Downloading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "O3KHGKqyeJp9",
        "outputId": "62d0b86a-27fe-44ff-e66f-7f65e110914c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model already exists\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Downloading the model\n",
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "Huggingface_Token = \"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\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown (Make sure you accepted the terms in https://huggingface.co/CompVis/stable-diffusion-v1-4)\n",
        "token=Huggingface_Token\n",
        "if token == \"\" and not os.path.exists('/content/stable-diffusion-v1-4'):\n",
        "  token=input(\"Insert your huggingface token :\")\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git clone \"https://USER:{token}@huggingface.co/CompVis/stable-diffusion-v1-4\"\n",
        "  if os.path.exists('/content/stable-diffusion-v1-4/unet/diffusion_pytorch_model.bin'):\n",
        "    clear_output()\n",
        "    print('DONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-4'):\n",
        "         print('Make sure you accepted the terms in https://huggingface.co/CompVis/stable-diffusion-v1-4')\n",
        "         time.sleep(5)\n",
        "         \n",
        "elif not os.path.exists('/content/stable-diffusion-v1-4'):\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git clone \"https://USER:{token}@huggingface.co/CompVis/stable-diffusion-v1-4\"\n",
        "  if os.path.exists('/content/stable-diffusion-v1-4/unet/diffusion_pytorch_model.bin'):\n",
        "    clear_output()\n",
        "    print('DONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-4'):\n",
        "         print('Make sure you accepted the terms in https://huggingface.co/CompVis/stable-diffusion-v1-4')\n",
        "         time.sleep(5)\n",
        "else:\n",
        "  print(\"Model already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1pH1oP-7yBZm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "#@markdown #Setting up\n",
        "#@markdown ---\n",
        "\n",
        "With_Prior_Preservation = \"Yes\" #@param [\"Yes\", \"No\"] \n",
        "#@markdown With the prior reservation method the results are more coherent and better, you will have to either upload around 200 pictures of the class you're training (dog, person, car, house ...), but more is better, if you don't upload them, it will automatically generate them at the cost of quality and time. For excellent results, manually filter around 400 images of the class and 50 pictures of the instance (a photo of yourself or your dog ...), try 2000 steps then tune it from there.\n",
        "\n",
        "MODEL_NAME=\"/content/stable-diffusion-v1-4\"\n",
        "\n",
        "#@markdown ### Training subject (is it a person ? a dog ? a car ? pick the correct category):\n",
        "SUBJECT_NAME= \"person\" #@param{type: 'string'}\n",
        "while SUBJECT_NAME==\"\":\n",
        "   SUBJECT_NAME=input('Input the class name (subject) :')\n",
        "  \n",
        "#@markdown ### Identifier (choose a unique identifier unknown by stable diffusion ):\n",
        "INSTANCE_NAME= \"brentbrent\" #@param{type: 'string'}\n",
        "while INSTANCE_NAME==\"\":\n",
        "   INSTANCE_NAME=input('Input the instance name (identifier) :')\n",
        "\n",
        "INSTANCE_DIR_OPTIONAL=\"/content/data/brentbrent\" #@param{type: 'string'}\n",
        "INSTANCE_DIR=INSTANCE_DIR_OPTIONAL\n",
        "while INSTANCE_DIR_OPTIONAL!=\"\" and not os.path.exists(str(INSTANCE_DIR)):\n",
        "    INSTANCE_DIR=input('The instance folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "\n",
        "#@markdown - If the number of instance pictures is large, it is preferable to specify directly the folder instead of uploading, leave EMPTY to upload.\n",
        "\n",
        "CLASS_DIR=\"/content/data/\"+ SUBJECT_NAME\n",
        "Number_of_subject_images=200#@param{type: 'number'}\n",
        "while Number_of_subject_images==None:\n",
        "     Number_of_subject_images=input('Input the number of subject images :')\n",
        "SUBJECT_IMAGES=Number_of_subject_images\n",
        "\n",
        "OUTPUT_DIR=\"/content/models/\"+ INSTANCE_NAME\n",
        "\n",
        "if INSTANCE_DIR_OPTIONAL==\"\":\n",
        "  INSTANCE_DIR=\"/content/data/\"+INSTANCE_NAME\n",
        "  !mkdir -p \"$INSTANCE_DIR\"\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(filename, INSTANCE_DIR)\n",
        "    clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PlpYjlXfhoOl",
        "outputId": "7171ec4a-214e-4dc3-ac22-bd911822e52b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LVCHYyYTIc61"
      },
      "outputs": [],
      "source": [
        "#@markdown ##[Optional] Upload or choose a folder of the class pictures (pictures of dogs if you're training on a dog), 200 is good, more is better, if you upload less than Number_of_subject_images, it will automatically generate the rest.\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "import shutil\n",
        "\n",
        "if (With_Prior_Preservation=='No'):\n",
        "  print(\"This training method doesn't require class images\")\n",
        "\n",
        "else:\n",
        "  CLASS_DIR=\"\" #@param{type: 'string'}\n",
        "  if (CLASS_DIR !=\"\") and os.path.exists(str(CLASS_DIR)):\n",
        "    CLASS_DIR=CLASS_DIR\n",
        "  elif (CLASS_DIR !=\"\") and not os.path.exists(str(CLASS_DIR)):\n",
        "    CLASS_DIR=input('The folder specified does not exist, use the colab file explorer to copy the path :')\n",
        "  elif (CLASS_DIR ==\"\"):\n",
        "    CLASS_DIR=\"/content/data/\"+ SUBJECT_NAME\n",
        "    !mkdir -p \"data/$SUBJECT_NAME\"\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "      shutil.move(filename, CLASS_DIR)\n",
        "      clear_output() \n",
        "\n",
        "#@markdown - To save time, if you specify a CLASS_DIR which is a folder that containes class images (eg: 200 pics of a dog), dreambooth will use this folder. \n",
        "#@markdown -Leave it empty if you want to upload\n",
        "\n",
        "#@markdown - Skip the cell if you want it to generate class (subject) images.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1-9QbkfAVYYU",
        "outputId": "b1ff65bb-d970-452d-b21b-e2edf19a91e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--num_cpu_threads_per_process` was set to `1` to improve out-of-box performance\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "Generating class images:  12% 6/50 [03:18<24:11, 32.99s/it]"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "else:\n",
        "  precision=\"fp16\"\n",
        "\n",
        "Training_Steps=\"1000\" #@param{type: 'string'}\n",
        "Seed=11111 #@param{type: 'number'}\n",
        "\n",
        "if With_Prior_Preservation=='No':\n",
        "  #@markdown ####More steps, better results, but longer training time\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"photo of {INSTANCE_NAME} {SUBJECT_NAME}\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=5e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps \n",
        "\n",
        "else:\n",
        "\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    --pretrained_model_name_or_path=\"$MODEL_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --class_data_dir=\"$CLASS_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --instance_prompt=\"photo of a {INSTANCE_NAME} {SUBJECT_NAME}\"\\\n",
        "    --class_prompt=\"photo of a {SUBJECT_NAME}\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=512 \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=5e-6 \\\n",
        "    --lr_scheduler=\"constant\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps \\\n",
        "    --num_class_images=$SUBJECT_IMAGES\n",
        "\n",
        "  \n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  if not os.path.exists('/content/convertosd.py'):\n",
        "    %cd /content    \n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "    clear_output()\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  !sed -i '202s@.*@    checkpoint_path= \"/content/gdrive/MyDrive/{INSTANCE_NAME}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  clear_output()\n",
        "  print(\"DONE, the CKPT model is in your Gdrive\")\n",
        "else:\n",
        "  print(\"Something went wrong\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iAZGngFcI8hq"
      },
      "outputs": [],
      "source": [
        "#@markdown # Test the trained model\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "import time\n",
        "\n",
        "INSTANCE__NAME=\"\" #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Leave empty if you want to use the current trained model\n",
        "\n",
        "if INSTANCE__NAME!=\"\":\n",
        "  INSTANCE_NAME=INSTANCE__NAME\n",
        "\n",
        "Use_Custom_Path = False #@param {type:\"boolean\"}\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  if Use_Custom_Path:\n",
        "    del INSTANCE_NAME\n",
        "except:\n",
        "  pass\n",
        "#@markdown - if checked, an input box will ask the full path to a desired model\n",
        "\n",
        "try:\n",
        "  INSTANCE_NAME\n",
        "  path_to_trained_model='/content/gdrive/MyDrive/'+INSTANCE_NAME+'.ckpt'\n",
        "except:\n",
        "  path_to_trained_model=input(\"It seems that you did not perform training during this session or you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n\")\n",
        "     \n",
        "while not os.path.exists(path_to_trained_model):\n",
        "   path_to_trained_model=input(\"The model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
        "\n",
        "         \n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/gdrive/MyDrive/\n",
        "    %mkdir sd\n",
        "    %cd sd\n",
        "    !git clone https://github.com/CompVis/stable-diffusion\n",
        "    !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "    !mkdir -p cache/{huggingface,torch}\n",
        "    %cd /content/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/huggingface ../root/.cache/\n",
        "    !ln -s /content/gdrive/MyDrive/sd/stable-diffusion-webui/cache/torch ../root/.cache/\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:  \n",
        "  if not os.path.exists('/content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion'):\n",
        "    !mkdir /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion/src\n",
        "    !git clone https://github.com/CompVis/taming-transformers\n",
        "    !git clone https://github.com/openai/CLIP\n",
        "    !mv /content/gdrive/MyDrive/sd/stable-diffusion/src/CLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/clip\n",
        "    !git clone https://github.com/TencentARC/GFPGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/GFPGAN/gfpgan /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/salesforce/BLIP\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/BLIP /content/gdrive/MyDrive/sd/stable-diffusion/src/blip\n",
        "    !git clone https://github.com/sczhou/CodeFormer\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/CodeFormer /content/gdrive/MyDrive/sd/stable-diffusion/src/codeformer\n",
        "    !git clone https://github.com/xinntao/Real-ESRGAN\n",
        "    !mv  /content/gdrive/MyDrive/sd/stable-diffusion/src/Real-ESRGAN/ /content/gdrive/MyDrive/sd/stable-diffusion/src/realesrgan\n",
        "    !git clone https://github.com/crowsonkb/k-diffusion.git\n",
        "    !cp -r /content/gdrive/MyDrive/sd/stable-diffusion/src/k-diffusion/k_diffusion /content/gdrive/MyDrive/sd/stable-diffusion-webui\n",
        "    !git clone https://github.com/Hafiidz/latent-diffusion\n",
        "    !cp -r  /content/gdrive/MyDrive/sd/stable-diffusion/ldm /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/usr/local/lib/python3.7/dist-packages/gradio-3.4b3.dist-info'):\n",
        "    %cd /content/\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.1\n",
        "    !wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.2\n",
        "    %mv Dependencies_AUT.1 Dependencies_AUT.7z.001\n",
        "    %mv Dependencies_AUT.2 Dependencies_AUT.7z.002\n",
        "    !7z x Dependencies_AUT.7z.001\n",
        "    time.sleep(2)\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/transformers-4.19.2.dist-info\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers\n",
        "    !rm -r /content/usr/local/lib/python3.7/dist-packages/diffusers-0.3.0.dist-info\n",
        "    !cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "    !rm -r /content/usr\n",
        "    !rm Dependencies_AUT.7z.001\n",
        "    !rm Dependencies_AUT.7z.002\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/ldm/modules\n",
        "    !wget -O attention.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/precompiled/attention.py\n",
        "    %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/modules\n",
        "    !wget -O paths.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/AUTOMATIC1111_files/paths.py\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion-webui/\n",
        "  time.sleep(1)\n",
        "  !wget -O webui.py https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.py\n",
        "  !sed -i 's@gpu_call).*@gpu_call) \\n        demo.queue(concurrency_count=111500)@' /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py\n",
        "Use_Gradio_Server = False #@param {type:\"boolean\"}\n",
        "#@markdown  - Only if you have trouble connecting to the local server\n",
        "\n",
        "with capture.capture_output() as cap: \n",
        "  %cd /content\n",
        "\n",
        "share=''\n",
        "if Use_Gradio_Server:\n",
        "  share='--share'\n",
        "  !sed -i '1037s@.*@            self.server_name = server_name@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = server_port@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\" if self.local_url.startswith(\"https\") else \"http\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "\n",
        "else:\n",
        "  share=''\n",
        "\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "  !sed -i '1037s@.*@            self.server_name = \"{srv[8:]}\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1039s@.*@            self.server_port = 443@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py\n",
        "  !sed -i '1043s@.*@            self.protocol = \"https\"@' /usr/local/lib/python3.7/dist-packages/gradio/blocks.py  \n",
        "          \n",
        "  !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\",@' /usr/local/lib/python3.7/dist-packages/gradio/strings.py\n",
        "  \n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/sd/stable-diffusion/\n",
        "\n",
        "!python /content/gdrive/MyDrive/sd/stable-diffusion-webui/webui.py $share --ckpt \"$path_to_trained_model\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bbKbx185zqlz",
        "P8aNBqn9JviD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}